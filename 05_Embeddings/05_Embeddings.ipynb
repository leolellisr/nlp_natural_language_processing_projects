{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210909_Aula 5 - Exercício_Leonardo de Lellis Rossi",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leolellisr/npl_natural_language_processing_projects/blob/main/05_Embeddings/05_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OG5DT_dm6mk"
      },
      "source": [
        "# Notebook de referência \n",
        "\n",
        "Nome: Leonardo de Lellis Rossi\n",
        "\n",
        "https://app.neptune.ai/leolellisr/nlp-imbd-large/e/NIMBL-39/charts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhpAkifICdJo"
      },
      "source": [
        "# Fixando a seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ozXD-xYCcrT"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHeZ9nAOEB0U"
      },
      "source": [
        "def set_seeds():\n",
        "  random.seed(123)\n",
        "  np.random.seed(123)\n",
        "  torch.manual_seed(123)\n",
        "  torch.cuda.manual_seed(123)\n",
        "set_seeds()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFdJz2KVeQw"
      },
      "source": [
        "## Preparando Dados "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMi_Kq65fPM"
      },
      "source": [
        "Primeiro, fazemos download do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wbnfzst5O3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a9a66f-e74c-4478-eb87-3a386a247f45"
      },
      "source": [
        "!wget -nc http://files.fast.ai/data/aclImdb.tgz \n",
        "!tar -xzf aclImdb.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘aclImdb.tgz’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Giyi5Rv_NIm"
      },
      "source": [
        "## Carregando o dataset\n",
        "\n",
        "Criaremos uma divisão de treino (80%) e validação (20%) artificialmente.\n",
        "\n",
        "Nota: Evitar de olhar ao máximo o dataset de teste para não ficar enviseado no que será testado. Em aplicações reais, o dataset de teste só estará disponível no futuro, ou seja, é quando o usuário começa a testar o seu produto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HIN_xLI_TuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43adb18b-1bd8-491a-f9b7-a3486709e561"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "def load_texts(folder):\n",
        "    texts = []\n",
        "    for path in os.listdir(folder):\n",
        "        with open(os.path.join(folder, path)) as f:\n",
        "            texts.append(f.read())\n",
        "    return texts\n",
        "\n",
        "x_train_pos = load_texts('aclImdb/train/pos')\n",
        "x_train_neg = load_texts('aclImdb/train/neg')\n",
        "x_test_pos = load_texts('aclImdb/test/pos')\n",
        "x_test_neg = load_texts('aclImdb/test/neg')\n",
        "\n",
        "x_train = x_train_pos + x_train_neg\n",
        "x_test = x_test_pos + x_test_neg\n",
        "y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n",
        "y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n",
        "\n",
        "# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n",
        "c = list(zip(x_train, y_train))\n",
        "random.shuffle(c)\n",
        "x_train, y_train = zip(*c)\n",
        "\n",
        "n_train = int(0.8 * len(x_train))\n",
        "\n",
        "x_valid = x_train[n_train:]\n",
        "y_valid = y_train[n_train:]\n",
        "x_train = x_train[:n_train]\n",
        "y_train = y_train[:n_train]\n",
        "\n",
        "print(len(x_train), 'amostras de treino.')\n",
        "print(len(x_valid), 'amostras de desenvolvimento.')\n",
        "print(len(x_test), 'amostras de teste.')\n",
        "\n",
        "print('3 primeiras amostras treino:')\n",
        "for x, y in zip(x_train[:3], y_train[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras treino:')\n",
        "for x, y in zip(x_train[-3:], y_train[-3:]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 primeiras amostras validação:')\n",
        "for x, y in zip(x_valid[:3], y_test[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras validação:')\n",
        "for x, y in zip(x_valid[-3:], y_valid[-3:]):\n",
        "    print(y, x[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000 amostras de treino.\n",
            "5000 amostras de desenvolvimento.\n",
            "25000 amostras de teste.\n",
            "3 primeiras amostras treino:\n",
            "False Realistic movie,sure,except for the fact that the characters don't look like to be scared. When Bill\n",
            "False DVD has become the equivalent of the old late night double-bill circuit, the last chance to catch ol\n",
            "True this is the first of a two part back-story to the conflict between the machines and mankind in the M\n",
            "3 últimas amostras treino:\n",
            "False This is, without a doubt, the most offensive \"chick flick\" I have seen in years, if not ever. The wr\n",
            "True I am going to go out on a limb, and actually defend \"Shades of Grey\" as a good clip-show episode, wh\n",
            "True Many people know how it feels when a loved one is lost. The feelings of pain, grief and sorrow can b\n",
            "3 primeiras amostras validação:\n",
            "True Netflix should mention this short feature on the info for Silk Stockings. Superior in every way to t\n",
            "True I've watched the first 17 episodes and this series is simply amazing! I haven't been this interested\n",
            "True I really did like this show, once upon a time. That is, until I realized all the faults in it. It's \n",
            "3 últimas amostras validação:\n",
            "True Hidden Frontier is notable for being the longest running internet-based Star Trek fan series. While \n",
            "True GBS wrote his own screen adaptation of this Nobel Prize winning play but didn't live to see it produ\n",
            "True I saw Heartland when it was first released in 1980 and I have just seen it again. It improves with a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiLnZh8fKXvm",
        "outputId": "1a4963d5-c65e-4807-cc1e-3786c48eca33"
      },
      "source": [
        "sum([len(item.split()) for item in x_train])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4689303"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNM4nM9-b6ga"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xNGaYP1cQpG"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "from torchtext.vocab import vocab\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KovGvvBmcIBt",
        "outputId": "fa73340a-2d1f-4a1c-d24f-1c9d4aa8186b"
      },
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "   print(torch. cuda. get_device_name(dev))\n",
        "else: \n",
        "   dev = \"cpu\" \n",
        "print(dev)\n",
        "device = torch.device(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_zTO7avmuxk"
      },
      "source": [
        "# Shuffle DS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzHdboz_lsM2",
        "outputId": "52d43218-627b-4de5-97ba-6897da57ae04"
      },
      "source": [
        "c = list(zip(x_train, y_train))\n",
        "d = list(zip(x_valid, y_valid))\n",
        "\n",
        "random.shuffle(c)\n",
        "x_valid, y_valid = zip(*d)\n",
        "x_train, y_train = zip(*c)\n",
        "len(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCBU1T9GcWJB"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TPZjKyTcZhE"
      },
      "source": [
        "def tokenizer(sentence):\n",
        "    #Beautiful soup to remove tags of sentences \n",
        "    removeTags = BeautifulSoup(sentence, 'html.parser') \n",
        "\n",
        "    # Getting list of words and remove numbers and ponctuation with regex\n",
        "    removeNotWords = re.sub('\\W+',' ', removeTags.text)\n",
        "    regex = re.compile('\\w+|[^\\w\\s]+')\n",
        "    re_split = regex.findall(removeNotWords.lower())\n",
        "    \n",
        "    re_split_without_numbers = [word for word in re_split if not word.isnumeric()]\n",
        "    return re_split_without_numbers\n",
        "x_train_token = tokenizer(' '.join(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCvhlPAOccqn"
      },
      "source": [
        "# Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfPj0M_ncgUi",
        "outputId": "9a32a9af-c952-4b17-cb88-0dc562d73d81"
      },
      "source": [
        "# Size Vocabulary\n",
        "size_vocab = 10000\n",
        "\n",
        "# Count tokens\n",
        "counterTokens = dict(Counter(x_train_token).most_common(size_vocab))\n",
        "\n",
        "# Define vocabulary with torch.vocab\n",
        "vocab_train = vocab(counterTokens, min_freq=1)\n",
        "vocab_train.set_default_index(len(vocab_train))\n",
        "\n",
        "print('len of train vocabulary is',len(vocab_train))\n",
        "\n",
        "bow_pipeline = lambda x: [vocab_train[token] for token in tokenizer(x)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of train vocabulary is 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyWo4o2KGOY9",
        "outputId": "e0ae49d7-0038-4fa6-bac9-de7d8395045d"
      },
      "source": [
        "print(bow_pipeline('This movie$#@ &*() is, amazing! fr33'))\n",
        "bow_pipeline('Thats something Thats something !$ This movie$#@ &*() is, amazing!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9, 16, 5, 473, 10000]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1585, 138, 1585, 138, 9, 16, 5, 473]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcCRJ7WhctgM"
      },
      "source": [
        "# Padding parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X9eAQBycwq9"
      },
      "source": [
        "max_pad = 200\n",
        "pad_idx = len(vocab_train)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywuCczADdRjG"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxpHcPV4dVzr"
      },
      "source": [
        "class Ex5_ds(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x, y, mode):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        y_label = int(self.y[index]) # bool to int\n",
        "        token_idx = bow_pipeline(self.x[index]) # Getting bow\n",
        "        token_idx = token_idx[:max_pad] # Remove tokens when len(tokens)>max_pad\n",
        "        \n",
        "        if self.mode == 'bow_hist': # same as \"Aula 4\"\n",
        "            all_tokens = torch.zeros(len(vocab_train)+1).long()\n",
        "            count_dict = Counter(token_idx)\n",
        "            dict_keys = list(count_dict.keys())\n",
        "            dict_values = torch.tensor(list(count_dict.values())).long()\n",
        "            all_tokens[dict_keys] = dict_values\n",
        "            all_tokens = all_tokens.float()\n",
        "\n",
        "        elif self.mode =='emb':\n",
        "            if len(token_idx) < max_pad: # when embedding, if len(tokens)<max_pad, they're completed with pad_idx\n",
        "                token_idx = token_idx + (max_pad - len(token_idx)) * [pad_idx]\n",
        "            assert len(token_idx) == max_pad # verify if I get exactly max_pad tokens\n",
        "\n",
        "            all_tokens = torch.tensor(token_idx).long()\n",
        "\n",
        "        return all_tokens, y_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-eM-mIJhtM-"
      },
      "source": [
        "# Install and config Neptune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdXlzed5Y9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e2090a-181a-43c0-f51d-904efaa973f9"
      },
      "source": [
        "! pip install neptune-client"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neptune-client in /usr/local/lib/python3.7/dist-packages (0.10.10)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from neptune-client) (5.4.8)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.25.11)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (0.18.2)\n",
            "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.0)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Requirement already satisfied: boto3==1.18.14 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.18.14)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.18)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (21.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Requirement already satisfied: bravado in /usr/local/lib/python3.7/dist-packages (from neptune-client) (11.0.3)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.14 in /usr/local/lib/python3.7/dist-packages (from boto3==1.18.14->neptune-client) (1.21.42)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3==1.18.14->neptune-client) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3==1.18.14->neptune-client) (0.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.14->boto3==1.18.14->neptune-client) (2.8.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune-client) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.2)\n",
            "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (5.17.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.13)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.6)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.17.5)\n",
            "Requirement already satisfied: jsonref in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (0.2)\n",
            "Requirement already satisfied: swagger-spec-validator>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.7.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2018.9)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.6.0)\n",
            "Requirement already satisfied: rfc3987 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client) (1.3.8)\n",
            "Requirement already satisfied: webcolors in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client) (1.11.1)\n",
            "Requirement already satisfied: strict-rfc3339 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client) (0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mud5SWY-hv3G",
        "outputId": "5c957b16-c02c-471f-f20b-618f974759ca"
      },
      "source": [
        "import neptune.new as neptune\n",
        "\n",
        "run = neptune.init(project='leolellisr/nlp-imbd-large', api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1NjY1YmJkZi1hYmM5LTQ3M2QtOGU1ZC1iZTFlNWY4NjE1NDQifQ==')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/leolellisr/nlp-imbd-large/e/NIMBL-39\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL7JjMH6kypS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSsvY4nQ1QDZ"
      },
      "source": [
        "Creating weights (W) and bias 2nd layer\n",
        "\n",
        "For linear/embedding + relu + linear implementation, didn't get same results.\n",
        "\n",
        "Needed to clone weights of bow_hist model and then .cat with zeros for padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlmO3NZA1TjX"
      },
      "source": [
        "# Input size: vocab_train+2 (unknown+pad)\n",
        "# Hidden size: 128\n",
        "#set_seeds()\n",
        "\n",
        "# Weights of 1st layer \n",
        "#fst_W = torch.rand(128, len(vocab_train)+2)\n",
        "\n",
        "# Weights of 2nd layer \n",
        "#snd_W = torch.rand(2, 128)\n",
        "\n",
        "# Bias 2nd layer \n",
        "#snd_bias = torch.rand(2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WTanKYrjghZ"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsUxPYgTjjov"
      },
      "source": [
        "class Ex5_model(torch.nn.Module):\n",
        "    def __init__(self, mode, input, hidden):\n",
        "        super(Ex5_model, self).__init__()\n",
        "        self.mode = mode\n",
        "        if mode == 'bow_hist': # same as \"Aula 4\"\n",
        "          self.fst_layer = torch.nn.Linear(input, hidden, bias=False, device=device)\n",
        "          \n",
        "          # didn't work\n",
        "          #self.fst_layer.load_state_dict(OrderedDict([('weight',  fst_W[:,:-1])]))\n",
        "        elif mode == 'emb':\n",
        "          self.fst_layer = torch.nn.Embedding(input, hidden, device=device, padding_idx=pad_idx)        \n",
        "          \n",
        "          # didn't work\n",
        "          #self.fst_layer.load_state_dict(OrderedDict([('weight',  fst_W.T)])) #same effect as _weight=fst_W.T in torch.nn.Embedding\n",
        "        else: print(\"Invalid mode\")\n",
        "\n",
        "        self.snd_linear_layer = torch.nn.Linear(hidden, 2, device=device, bias=False)\n",
        "        \n",
        "        # didn't work\n",
        "        #self.snd_linear_layer.load_state_dict(OrderedDict([('weight',  snd_W), ('bias', snd_bias)]))\n",
        "                    \n",
        "        self.relu = torch.nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fst_layer(x)\n",
        "        if self.mode == 'emb': x = torch.sum(x, dim=1) \n",
        "        x = self.relu(x)\n",
        "        x = self.snd_linear_layer(x)\n",
        "        #x = self.relu(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjGNVzQPIw10"
      },
      "source": [
        "#class Ex5_model_emb(torch.nn.Module):\n",
        "#    def __init__(self,input, hidden, fst_W, snd_W, snd_bias):\n",
        "#        super(Ex5_model_emb, self).__init__()\n",
        "#        self.fst_layer = torch.nn.Embedding(input, hidden, device=device, _weight=fst_W.T, padding_idx=pad)        \n",
        "#        self.snd_linear_layer = torch.nn.Linear(hidden, 2, device=device)\n",
        "#        self.snd_linear_layer.load_state_dict(OrderedDict([('weight',  snd_W), ('bias', snd_bias)]))\n",
        "#        self.relu = torch.nn.ReLU(),\n",
        "#    def forward(self, x):\n",
        "#        x = self.fst_layer(x)\n",
        "#        x = torch.sum(x, dim=1) \n",
        "#        x = torch.relu(x)\n",
        "#        x = self.snd_linear_layer(x)\n",
        "#        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4H6a-3_OolU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZp1MdLU1Wxt"
      },
      "source": [
        "# Summary models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOYLOXuz1a2u",
        "outputId": "d00d399d-0ee3-4919-c9af-857ce7e3d4f8"
      },
      "source": [
        "# Model BoW Freq\n",
        "ex5_model = Ex5_model('bow_hist',len(vocab_train)+1, 128)\n",
        "ex5_model.to(device)\n",
        "#print(ex5_model.fst_layer.weight)\n",
        "#print(ex5_model.fst_layer.weight.shape)\n",
        "\n",
        "# Summary Model BoW Freq\n",
        "print(ex5_model)\n",
        "\n",
        "# Model Embedding\n",
        "ex5_model_emb = Ex5_model('emb',len(vocab_train)+2, 128)\n",
        "ex5_model_emb.to(device)\n",
        "#print(ex5_model_emb.fst_layer.weight)\n",
        "#print(ex5_model_emb.fst_layer.weight.shape)\n",
        "\n",
        "# Summary Model Embedding\n",
        "print(ex5_model_emb)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ex5_model(\n",
            "  (fst_layer): Linear(in_features=10001, out_features=128, bias=False)\n",
            "  (snd_linear_layer): Linear(in_features=128, out_features=2, bias=False)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "Ex5_model(\n",
            "  (fst_layer): Embedding(10002, 128, padding_idx=10001)\n",
            "  (snd_linear_layer): Linear(in_features=128, out_features=2, bias=False)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V05hzbtwluYW"
      },
      "source": [
        "# Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm-EmNuxlww7"
      },
      "source": [
        "n_epochs = 5\n",
        "learningRate = 0.0001\n",
        "\n",
        "# CrossEntropyLoss as loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sH14jmmlzwn"
      },
      "source": [
        "def train_loop(dataloader_train, dataloader_val, hyperparameters, model):\n",
        "    train_loss_a=[] \n",
        "    val_loss_a=[] \n",
        "    total_acc_a=[]\n",
        "    # Gradient descent\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['learning_rate'])\n",
        "    min_val_loss = 10e9\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(hyperparameters['n_epochs']):\n",
        "      # print(f'Model: {hyperparameters[\"mode\"]} - Weights 1st layer')\n",
        "      # print(model.fst_layer.weight.shape)\n",
        "      # print(model.fst_layer.weight)\n",
        "      train_loss = 0\n",
        "      model.train()\n",
        "      for x_train, y_train in dataloader_train:\n",
        "            # transform to one dimention\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "        #print(x_train)\n",
        "        #print(x_train.shape)    \n",
        "        #print(y_train) \n",
        "        #print(y_train.shape) \n",
        "            # predict \n",
        "        outputs = model(x_train)\n",
        "\n",
        "            # batch loss\n",
        "        batch_loss = criterion(outputs, y_train)\n",
        "\n",
        "            # reset gradients, backpropagation, optimizer step and sum loss\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += batch_loss.item()\n",
        "            #print(f'{hyperparameters[\"name\"]}_train/batch_loss: {batch_loss}')\n",
        "        run[f'{hyperparameters[\"mode\"]}_train/batch_loss'].log(batch_loss)\n",
        "\n",
        "      train_loss = train_loss / len(dataloader_train.dataset)\n",
        "      train_loss_a.append(train_loss)\n",
        "        #print(f'Epoch {epoch} / {hyperparameters[\"name\"]} train loss: {train_loss}')\n",
        "      run[f'{hyperparameters[\"mode\"]}_train/train_loss'].log(train_loss) \n",
        "\n",
        "        # Validation (end of epoch).\n",
        "      total_loss = 0\n",
        "      total_acc = 0\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for x_val, y_val in dataloader_val:\n",
        "          x_val = x_val.to(device)\n",
        "          y_val = y_val.to(device)\n",
        "\n",
        "                # predict\n",
        "          outputs = model(x_val)\n",
        "\n",
        "                # batch loss\n",
        "          batch_loss = criterion(outputs, y_val)\n",
        "          preds = outputs.argmax(dim=1)\n",
        "\n",
        "                # val acc\n",
        "          batch_acc = (preds == y_val).sum()\n",
        "          total_loss += batch_loss\n",
        "          total_acc += batch_acc\n",
        "\n",
        "      val_loss = total_loss / len(dataloader_val.dataset)\n",
        "      val_loss_a.append(val_loss)\n",
        "      run[f'{hyperparameters[\"mode\"]}_val/val_loss'].log(val_loss)\n",
        "      run[f'{hyperparameters[\"mode\"]}_val/val_acuracy'].log(total_acc / len(dataloader_val.dataset))\n",
        "      total_acc_a.append(total_acc / len(dataloader_val.dataset))\n",
        "     \n",
        "      print(f'Model: {hyperparameters[\"mode\"]}, Epoch: {epoch+1}/{hyperparameters[\"n_epochs\"]} - train_loss: {train_loss} - val_loss: {val_loss} - acc: {total_acc / len(dataloader_val.dataset)*100} %')\n",
        "\n",
        "        # Save best model\n",
        "      if val_loss < min_val_loss:\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        min_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "        print(f'Model: {hyperparameters[\"mode\"]} - best model in epoch: {best_epoch+1}')\n",
        "    return train_loss_a, val_loss_a, total_acc_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwKO7MdCytAq"
      },
      "source": [
        "# Function to test acc\n",
        "def predict(model, inputs):\n",
        "    outputs = model(inputs)\n",
        "    _, predicts = torch.max(outputs, 1)\n",
        "    return predicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9tqydzXcCrd"
      },
      "source": [
        "\n",
        "\n",
        "# List to Dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE6Qfe6vxnnX"
      },
      "source": [
        "# Transform list to dict\n",
        "x_train = {num: i for num, i in enumerate(x_train)}\n",
        "y_train = {num: i for num, i in enumerate(y_train)}\n",
        "x_valid = {num: i for num, i in enumerate(x_valid)}\n",
        "y_valid = {num: i for num, i in enumerate(y_valid)}\n",
        "x_test = {num: i for num, i in enumerate(x_test)}\n",
        "y_test = {num: i for num, i in enumerate(y_test)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vqPIerkoKfk"
      },
      "source": [
        "# BoW Hist sem Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K5za75cYVIW"
      },
      "source": [
        "set_seeds()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j1uNbcRSOv7",
        "outputId": "46a823b5-3fc0-455b-e1b2-68c0292e8834"
      },
      "source": [
        "# Defining model\n",
        "model_bow = Ex5_model('bow_hist', len(vocab_train)+1, 128)\n",
        "\n",
        "# Saving weights list to use in embedding model\n",
        "bow_weights = [model_bow.fst_layer.weight.clone(), model_bow.snd_linear_layer.weight.clone()]\n",
        "\n",
        "model_bow.to(device)\n",
        "print(f'bow_hist model - Weights shape 1st Layer: {model_bow.fst_layer.weight.shape}')\n",
        "print(f'bow_hist model - Weights shape 2nd Layer: {model_bow.snd_linear_layer.weight.shape}')\n",
        "#print(model_bow.fst_layer.weight)\n",
        "#print(model_bow.snd_linear_layer.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bow_hist model - Weights shape 1st Layer: torch.Size([128, 10001])\n",
            "bow_hist model - Weights shape 2nd Layer: torch.Size([2, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts5gD8qYxfWF"
      },
      "source": [
        "\n",
        "hyperparameters = { \"mode\": \"bow_hist\",\n",
        "          \"learning_rate\": 1e-4,\n",
        "          \"n_epochs\": 5,\n",
        "          \"batch_size\": 50,\n",
        "          \"hidden_size\": 128 }\n",
        "\n",
        "#model_bow = Ex5_model(hyperparameters['mode'], len(vocab_train)+1,  hyperparameters['hidden_size'])\n",
        "\n",
        "\n",
        "train_ds = Ex5_ds(x_train, y_train, hyperparameters['mode'])\n",
        "val_ds = Ex5_ds(x_valid, y_valid, hyperparameters['mode'])\n",
        "dataloader_train = DataLoader(train_ds, batch_size=hyperparameters['batch_size'], shuffle=False)\n",
        "dataloader_val = DataLoader(val_ds, batch_size=hyperparameters['batch_size'], shuffle=False)  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jkq7SWKO6HC",
        "outputId": "804cfb1f-44e0-474d-8aa5-e29594e35ebe"
      },
      "source": [
        "train_loss_bow, val_loss_bow, acc_bow = train_loop(dataloader_train, dataloader_val, hyperparameters, model_bow)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: bow_hist, Epoch: 1/5 - train_loss: 0.009897605769336223 - val_loss: 0.007173544727265835 - acc: 86.29999542236328 %\n",
            "Model: bow_hist - best model in epoch: 1\n",
            "Model: bow_hist, Epoch: 2/5 - train_loss: 0.005991089477390051 - val_loss: 0.006133963819593191 - acc: 87.63999938964844 %\n",
            "Model: bow_hist - best model in epoch: 2\n",
            "Model: bow_hist, Epoch: 3/5 - train_loss: 0.004725101256370544 - val_loss: 0.005948099307715893 - acc: 87.87999725341797 %\n",
            "Model: bow_hist - best model in epoch: 3\n",
            "Model: bow_hist, Epoch: 4/5 - train_loss: 0.003953803751245141 - val_loss: 0.006029663607478142 - acc: 87.95999908447266 %\n",
            "Model: bow_hist, Epoch: 5/5 - train_loss: 0.003383462906628847 - val_loss: 0.006235369481146336 - acc: 87.75999450683594 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgAcFzU-yW7z"
      },
      "source": [
        "del train_ds\n",
        "del val_ds\n",
        "del dataloader_train\n",
        "del dataloader_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGifQN2eyeLc",
        "outputId": "54a80823-1dc5-43aa-91ad-bd393dbd90ba"
      },
      "source": [
        "test_ds = Ex5_ds(x_test, y_test, hyperparameters['mode'])\n",
        "dataloader_test = DataLoader(test_ds, batch_size=hyperparameters['batch_size'], shuffle=False)  \n",
        "total_acc = 0     \n",
        "with torch.no_grad():\n",
        "  for x_t, y_t in dataloader_test:\n",
        "    x_t = x_t.to(device)\n",
        "    #print(x_t.shape)\n",
        "    y_t = y_t.to(device)\n",
        "    #print(y_t.shape)\n",
        "    outputs = model_bow(x_t)\n",
        "    #print(outputs.shape)\n",
        "\n",
        "    #preds = outputs > 0.5\n",
        "\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    #print(preds.shape)\n",
        "\n",
        "    # test acc\n",
        "    batch_acc = (preds == y_t).sum()\n",
        "    total_acc += batch_acc\n",
        "  test_acc = total_acc / len(dataloader_test.dataset)\n",
        "\n",
        "  print(f\"BoW Hist Acc: {test_acc*100} %\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Hist Acc: 85.31999206542969 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5ReuZpdz5Fl"
      },
      "source": [
        "del test_ds\n",
        "del dataloader_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqQXJbB-31dR"
      },
      "source": [
        "\n",
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoAC7RVyS0LA"
      },
      "source": [
        "set_seeds()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EUKiZTCEvpV"
      },
      "source": [
        "zeros = torch.zeros(128, 1) \n",
        "zeros = zeros.to(device) # need to compute in the same device\n",
        "\n",
        "pad_weight = torch.cat([bow_weights[0], zeros], dim=1) # concatenating zeros to end of weights - PAD\n",
        "emb_weights = OrderedDict([\n",
        "    ('fst_layer.weight',  pad_weight.T),\n",
        "    ('snd_linear_layer.weight',  bow_weights[1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrXDEz_0S2wd",
        "outputId": "00d8d0b3-f6e6-4694-c0a3-e1ce92728d83"
      },
      "source": [
        "# Defining model\n",
        "ex5_model_emb = Ex5_model('emb',len(vocab_train)+2, 128)\n",
        "\n",
        "# Loading weights\n",
        "ex5_model_emb.load_state_dict(emb_weights)\n",
        "\n",
        "print(f'emb model - Weights shape 1st Layer: {ex5_model_emb.fst_layer.weight.shape}')\n",
        "print(f'emb model - Weights shape 2nd Layer: {ex5_model_emb.snd_linear_layer.weight.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb model - Weights shape 1st Layer: torch.Size([10002, 128])\n",
            "emb model - Weights shape 2nd Layer: torch.Size([2, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyrKBDRv3yvb",
        "outputId": "dc68e207-cd5a-42b5-c30f-5e66a6d48b9d"
      },
      "source": [
        "\n",
        "hyperparameters = { \"mode\": \"emb\",\n",
        "          \"learning_rate\": 1e-4,\n",
        "          \"n_epochs\": 5,\n",
        "          \"batch_size\": 50,\n",
        "          \"hidden_size\": 128 }\n",
        "\n",
        "#ex5_model_emb = Ex5_model(hyperparameters['mode'], len(vocab_train)+2, hyperparameters['hidden_size'])\n",
        "ex5_model_emb.to(device)\n",
        "\n",
        "\n",
        "\n",
        "train_ds = Ex5_ds(x_train, y_train, hyperparameters['mode'])\n",
        "val_ds = Ex5_ds(x_valid, y_valid, hyperparameters['mode'])\n",
        "dataloader_train = DataLoader(train_ds, batch_size=hyperparameters['batch_size'], shuffle=False)\n",
        "dataloader_val = DataLoader(val_ds, batch_size=hyperparameters['batch_size'], shuffle=False)       \n",
        "train_loss_emb, val_loss_emb, acc_emb = train_loop(dataloader_train, dataloader_val, hyperparameters, ex5_model_emb)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: emb, Epoch: 1/5 - train_loss: 0.009897605761885643 - val_loss: 0.007173544727265835 - acc: 86.29999542236328 %\n",
            "Model: emb - best model in epoch: 1\n",
            "Model: emb, Epoch: 2/5 - train_loss: 0.005991089464724064 - val_loss: 0.006133963819593191 - acc: 87.63999938964844 %\n",
            "Model: emb - best model in epoch: 2\n",
            "Model: emb, Epoch: 3/5 - train_loss: 0.004725101243704557 - val_loss: 0.005948099307715893 - acc: 87.87999725341797 %\n",
            "Model: emb - best model in epoch: 3\n",
            "Model: emb, Epoch: 4/5 - train_loss: 0.003953803734853864 - val_loss: 0.006029663607478142 - acc: 87.95999908447266 %\n",
            "Model: emb, Epoch: 5/5 - train_loss: 0.0033834629133343698 - val_loss: 0.006235369946807623 - acc: 87.75999450683594 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkjwnJ994NVO"
      },
      "source": [
        "del train_ds\n",
        "del val_ds\n",
        "del dataloader_train\n",
        "del dataloader_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHi0bGmq4Zj5",
        "outputId": "bf86411e-39b6-413c-f63a-a486ab5dc24c"
      },
      "source": [
        "test_ds = Ex5_ds(x_test, y_test, hyperparameters['mode'])\n",
        "dataloader_test = DataLoader(test_ds, batch_size=hyperparameters['batch_size'], shuffle=False)  \n",
        "total_acc = 0     \n",
        "with torch.no_grad():\n",
        "  for x_t, y_t in dataloader_test:\n",
        "    x_t = x_t.to(device)\n",
        "    #print(x_t.shape)\n",
        "    y_t = y_t.to(device)\n",
        "    #print(y_t.shape)\n",
        "    outputs = ex5_model_emb(x_t)\n",
        "    #print(outputs.shape)\n",
        "\n",
        "    #preds = outputs > 0.5\n",
        "\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    #print(preds.shape)\n",
        "\n",
        "    # test acc\n",
        "    batch_acc = (preds == y_t).sum()\n",
        "    total_acc += batch_acc\n",
        "  test_acc = total_acc / len(dataloader_test.dataset)\n",
        "\n",
        "  print(f\"Embedding Acc: {test_acc*100} %\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Acc: 85.31999206542969 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p8QVyuN4h83"
      },
      "source": [
        "del test_ds\n",
        "del dataloader_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnOug2UOWaqi"
      },
      "source": [
        "#  Verify if BoW Freq. and Embedding models had same results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJqylokRApUS",
        "outputId": "3b237dd0-7eeb-43e0-ed2b-8c7d462c1892"
      },
      "source": [
        "print(f\"Train loss BoW Freq. {train_loss_bow}\")\n",
        "print(f\"Train loss Embedding {train_loss_emb}\")\n",
        "\n",
        "print(f\"Val loss BoW Freq. {val_loss_bow}\")\n",
        "print(f\"Val loss Embedding {val_loss_emb}\")\n",
        "\n",
        "print(f\"Acc BoW Freq. {acc_bow}\")\n",
        "print(f\"Acc Embedding {acc_emb}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss BoW Freq. [0.009897605769336223, 0.005991089477390051, 0.004725101256370544, 0.003953803751245141, 0.003383462906628847]\n",
            "Train loss Embedding [0.009897605761885643, 0.005991089464724064, 0.004725101243704557, 0.003953803734853864, 0.0033834629133343698]\n",
            "Val loss BoW Freq. [tensor(0.0072, device='cuda:0'), tensor(0.0061, device='cuda:0'), tensor(0.0059, device='cuda:0'), tensor(0.0060, device='cuda:0'), tensor(0.0062, device='cuda:0')]\n",
            "Val loss Embedding [tensor(0.0072, device='cuda:0'), tensor(0.0061, device='cuda:0'), tensor(0.0059, device='cuda:0'), tensor(0.0060, device='cuda:0'), tensor(0.0062, device='cuda:0')]\n",
            "Acc BoW Freq. [tensor(0.8630, device='cuda:0'), tensor(0.8764, device='cuda:0'), tensor(0.8788, device='cuda:0'), tensor(0.8796, device='cuda:0'), tensor(0.8776, device='cuda:0')]\n",
            "Acc Embedding [tensor(0.8630, device='cuda:0'), tensor(0.8764, device='cuda:0'), tensor(0.8788, device='cuda:0'), tensor(0.8796, device='cuda:0'), tensor(0.8776, device='cuda:0')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiztHbsJmnGa"
      },
      "source": [
        "assert torch.allclose(torch.tensor(train_loss_bow), torch.tensor(train_loss_emb), rtol=1e-05, atol=1e-08) and torch.allclose(torch.tensor(val_loss_bow), torch.tensor(val_loss_emb), rtol=1e-05, atol=1e-08) and torch.allclose(torch.tensor(acc_bow), torch.tensor(acc_emb), rtol=1e-05, atol=1e-08) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HllL9D_Ku6z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHivCBm6qzBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500a5e35-770e-4eb8-c3dd-7fc4bb1b63cb"
      },
      "source": [
        "run.stop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Waiting for the remaining 15 operations to synchronize with Neptune. Do not kill this process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All 15 operations synced, thanks for waiting!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvtzXeKztoLA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}